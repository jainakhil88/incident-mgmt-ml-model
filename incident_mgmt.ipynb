{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "       \n",
    "class Model(object):\n",
    "\n",
    "    categorical_non_ordinal_features = ['incident_state', 'active', 'made_sla','contact_type','knowledge','u_priority_confirmation', 'notify']\n",
    "    categorical_ordinal_features = [ 'impact', 'urgency', 'priority']\n",
    "    categorical_features = categorical_non_ordinal_features+categorical_ordinal_features\n",
    "    numerical_features = ['reassignment_count', 'reopen_count', 'sys_mod_count']\n",
    "    temporal_features = ['opened_at','sys_updated_at', 'closed_at']\n",
    "    mixed_features = ['number','caller_id', 'sys_created_by','opened_by','sys_updated_by', 'location',\n",
    "                  'category', 'subcategory', 'u_symptom', 'assignment_group', 'assigned_to', 'closed_code', 'resolved_by']\n",
    "    \n",
    "    mixed_features_engineered_columns= [\"caller_id_num\", \"sys_created_by_num\",\"sys_updated_by_num\",\n",
    "                                    \"opened_by_num\", \"location_num\",\"category_num\",\"subcategory_num\",\n",
    "                                    \"u_symptom_num\",\"assignment_group_num\",\"assigned_to_num\",\n",
    "                                    \"closed_code_num\",\"resolved_by_num\"]\n",
    "    \n",
    "    columns_to_be_dropped = [\"caller_id\", \"number\", \"opened_by\", \"sys_created_by\",\n",
    "              \"sys_updated_by\",\"location\",\"category\",\"subcategory\", \"u_symptom\",\"assignment_group\",\n",
    "              \"assigned_to\",\"closed_code\",\"resolved_by\", \"incident_number\",'opened_at','sys_updated_at', 'closed_at']\n",
    "    \n",
    "    temporal_number_features=[\"sys_updated_at_ms\"]\n",
    "\n",
    "    date_format='%d-%m-%Y %H:%M'\n",
    "    \n",
    "    float_data_type_features=['reassignment_count', 'reopen_count', 'sys_mod_count','sys_updated_at_ms']\n",
    "\n",
    "    int_data_type_features=['impact','urgency','priority','caller_id_num','sys_updated_by_num','location_num', \n",
    "                            'category_num', 'subcategory_num', 'closed_code_num', 'resolved_by_num', 'incident_state_Awaiting Evidence',\n",
    "                            'incident_state_Awaiting Problem','incident_state_Awaiting User Info',\n",
    "                            'incident_state_Awaiting Vendor', 'incident_state_Closed','incident_state_New',\n",
    "                            'incident_state_Resolved','active_True','made_sla_True', 'contact_type_Email','contact_type_IVR',\n",
    "                            'contact_type_Phone', 'contact_type_Self service','knowledge_True','u_priority_confirmation_True',\n",
    "                            'notify_Send Email','sys_created_by_num','u_symptom_num','opened_by_num', 'assignment_group_num','assigned_to_num']\n",
    "\n",
    "    saved_model_directory=\".\"+os.sep+\"saved_models\"+os.sep\n",
    "    \n",
    "    incident_state_simple_imputer=None\n",
    "    \n",
    "    non_ordinal_ohe=None\n",
    "    \n",
    "    label_encoder_impact = None\n",
    "    label_encoder_urgency = None\n",
    "    label_encoder_priority = None\n",
    "    \n",
    "    numerical_standard_scaler = None\n",
    "    \n",
    "    temporal_number_scaler = None\n",
    "    \n",
    "    assigned_to_num_rfc = None\n",
    "    assignment_group_num_rfc = None\n",
    "    opened_by_num_rfc = None\n",
    "    sys_created_by_num_rfc = None\n",
    "    u_symptom_num_rfc = None\n",
    "    \n",
    "    most_frequent_simple_imputer_for_zero_value = None\n",
    "    \n",
    "    lgbm_regressor = None\n",
    "    \n",
    "    def memory_usage_psutil(self):\n",
    "        # return the memory usage in MB\n",
    "        process = psutil.Process(os.getpid())\n",
    "        mem = process.memory_info()[0] / float(1024 ** 2)\n",
    "        return mem\n",
    "    \n",
    "    def load_pickle_to_obj(self, filename):\n",
    "        obj = None\n",
    "        with open(filename, 'rb') as f:\n",
    "            obj=pickle.load(f)\n",
    "        return obj\n",
    "    \n",
    "    def load_joblib_to_obj(self, filename):\n",
    "        loaded_model = joblib.load(filename)\n",
    "        return loaded_model\n",
    "    \n",
    "    def impute_particular_column_with_saved_model(self, df, column_to_be_imputed, imputer_model):\n",
    "         df[column_to_be_imputed] = df[column_to_be_imputed].astype('int')\n",
    "         impute_pred_for_df = imputer_model.predict(df.drop(columns=[column_to_be_imputed]))\n",
    "         df[column_to_be_imputed] = impute_pred_for_df\n",
    "         return df\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # df=pd.read_csv('./data/incident_event_log.csv')\n",
    "       \n",
    "        # df=df.replace({-100: np.NAN})\n",
    "        \n",
    "        self.non_ordinal_ohe= pickle.load(open(self.saved_model_directory+\"non_ordinal_ohe.pkl\", 'rb'))       \n",
    "        \n",
    "        \n",
    "        print(\"incident_state_simple_imputer exists\"+str(os.path.exists(self.saved_model_directory+\"incident_state_simple_imputer.pkl\")))\n",
    "        \n",
    "        \n",
    "        self.incident_state_simple_imputer = pickle.load(open(self.saved_model_directory+\"incident_state_simple_imputer.pkl\", 'rb'))\n",
    "        \n",
    "        print(\"incident_state_simple_imputer object=\"+str(self.incident_state_simple_imputer))\n",
    "        \n",
    "        # df[\"incident_state\"] = self.incident_state_simple_imputer.fit_transform(df[[\"incident_state\"]]).ravel()\n",
    "        \n",
    "        # df=None\n",
    "        \n",
    "        self.label_encoder_impact = self.load_pickle_to_obj(self.saved_model_directory+\"label_encoder_impact.pkl\")\n",
    "        \n",
    "        \n",
    "        self.label_encoder_urgency = self.load_pickle_to_obj(self.saved_model_directory+\"label_encoder_urgency.pkl\")\n",
    "        \n",
    "        \n",
    "        self.label_encoder_priority = self.load_pickle_to_obj(self.saved_model_directory+\"label_encoder_priority.pkl\")\n",
    "        \n",
    "        \n",
    "        self.numerical_standard_scaler = self.load_pickle_to_obj(self.saved_model_directory+\"numerical_standard_scaler.pkl\")\n",
    "        \n",
    "        \n",
    "        self.temporal_number_scaler = self.load_pickle_to_obj(self.saved_model_directory+\"temporal_number_scaler.pkl\")\n",
    "        \n",
    "        self.assigned_to_num_rfc = self.load_joblib_to_obj(self.saved_model_directory+\"assigned_to_num_rfc.sav\")      \n",
    "        self.assignment_group_num_rfc = self.load_joblib_to_obj(self.saved_model_directory+\"assignment_group_num_rfc.sav\")\n",
    "        self.opened_by_num_rfc = self.load_joblib_to_obj(self.saved_model_directory+\"opened_by_num_rfc.sav\")\n",
    "        self.sys_created_by_num_rfc = self.load_joblib_to_obj(self.saved_model_directory+\"sys_created_by_num_rfc.sav\")\n",
    "        self.u_symptom_num_rfc = self.load_joblib_to_obj(self.saved_model_directory+\"u_symptom_num_rfc.sav\")\n",
    "        \n",
    "        self.most_frequent_simple_imputer_for_zero_value = self.load_pickle_to_obj(self.saved_model_directory+\"most_frequent_simple_imputer_for_zero_value.pkl\")\n",
    "        \n",
    "        self.lgbm_regressor = self.load_joblib_to_obj(self.saved_model_directory+\"lgbm_reg_model.sav\")\n",
    "        print(\"init called\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def predict(self, df: pd.DataFrame):\n",
    "        \n",
    "        #removing unused columns        \n",
    "        df = df.drop(['cmdb_ci','problem_id','rfc','vendor','caused_by', 'resolved_at', 'sys_created_at'], axis=1)    \n",
    "        \n",
    "        #replacing missing values ? with None\n",
    "        df=df.replace({'?': None})\n",
    "        df=df.replace({-100: np.NAN})\n",
    "        \n",
    "        #converting to string/object type, this is for case where -100 was only passed in incident state for single row and pandas treat it as float\n",
    "        df['incident_state']=df['incident_state'].astype(object)\n",
    "        \n",
    "        #converting to date time format\n",
    "        df['opened_at'] = pd.to_datetime(df.opened_at, format=self.date_format)\n",
    "        df['sys_updated_at'] = pd.to_datetime(df.sys_updated_at, format=self.date_format)\n",
    "        df['closed_at'] = pd.to_datetime(df.closed_at, format=self.date_format)\n",
    "\n",
    "        #calculatig y / target variable\n",
    "        df['time_taken_to_complete'] = (df['closed_at'] - df['opened_at'])/ pd.Timedelta(days=1)\n",
    "        \n",
    "        #impute missing incident state if its value is -100 using simple imputer\n",
    "        df[\"incident_state\"]=self.incident_state_simple_imputer.transform(df[[\"incident_state\"]]).ravel()\n",
    "        \n",
    "        #remove the string prefix part from all the columns\n",
    "        df[\"incident_number\"] = df[\"number\"].str.replace(\"INC\", \"\")\n",
    "        \n",
    "        '''Capturing numerical part for caller_id feature, remove Caller word from the feature '''\n",
    "        df[\"caller_id_num\"] = df[\"caller_id\"].str.replace(\"Caller\", \"\")\n",
    "        df[[\"caller_id_num\"]] = df[[\"caller_id_num\"]].fillna(0)\n",
    "        \n",
    "        df[\"sys_created_by_num\"] = df[\"sys_created_by\"].str.replace(\"Created by\", \"\")\n",
    "        df[[\"sys_created_by_num\"]] = df[[\"sys_created_by_num\"]].fillna(0)\n",
    "        \n",
    "        df[\"sys_updated_by_num\"] = df[\"sys_updated_by\"].str.replace(\"Updated by\", \"\")\n",
    "        df[[\"sys_updated_by_num\"]] = df[[\"sys_updated_by_num\"]].fillna(0)\n",
    "        \n",
    "        df[\"opened_by_num\"] = df[\"opened_by\"].str.replace(\"Opened by\", \"\")\n",
    "        df[[\"opened_by_num\"]] = df[[\"opened_by_num\"]].fillna(0)\n",
    "        \n",
    "        df[\"location_num\"] = df[\"location\"].str.replace(\"Location\", \"\")\n",
    "        df[[\"location_num\"]] = df[[\"location_num\"]].fillna(0)\n",
    "        \n",
    "        df[\"category_num\"] = df[\"category\"].str.replace(\"Category\", \"\")\n",
    "        df[[\"category_num\"]] = df[[\"category_num\"]].fillna(0)\n",
    "        \n",
    "        df[\"subcategory_num\"] = df[\"subcategory\"].str.replace(\"Subcategory\", \"\")\n",
    "        df[[\"subcategory_num\"]] = df[[\"subcategory_num\"]].fillna(0)\n",
    "        \n",
    "        df[\"u_symptom_num\"] = df[\"u_symptom\"].str.replace(\"Symptom\", \"\")\n",
    "        df[[\"u_symptom_num\"]] = df[[\"u_symptom_num\"]].fillna(0)\n",
    "        \n",
    "        df[\"assignment_group_num\"] = df[\"assignment_group\"].str.replace(\"Group\", \"\")\n",
    "        df[[\"assignment_group_num\"]] = df[[\"assignment_group_num\"]].fillna(0)\n",
    "        \n",
    "        df[\"assigned_to_num\"] = df[\"assigned_to\"].str.replace(\"Resolver\", \"\")\n",
    "        df[[\"assigned_to_num\"]] = df[[\"assigned_to_num\"]].fillna(0)\n",
    "        \n",
    "        df[\"closed_code_num\"] = df[\"closed_code\"].str.replace(\"code\", \"\")\n",
    "        df[[\"closed_code_num\"]] = df[[\"closed_code_num\"]].fillna(0)\n",
    "\n",
    "        df[\"resolved_by_num\"] = df[\"resolved_by\"].str.replace(\"Resolved by\", \"\")\n",
    "        df[[\"resolved_by_num\"]] = df[[\"resolved_by_num\"]].fillna(0)\n",
    "\n",
    "\n",
    "        temp=self.non_ordinal_ohe.transform(df[self.categorical_non_ordinal_features])\n",
    "        one_hot_encoded_column_names = self.non_ordinal_ohe.get_feature_names(self.categorical_non_ordinal_features)\n",
    "        one_hot_encoded_df =  pd.DataFrame(temp, columns= one_hot_encoded_column_names, index=df.index)\n",
    "        df = pd.concat([df, one_hot_encoded_df], axis='columns')\n",
    "        df = df.drop(columns=self.categorical_non_ordinal_features)\n",
    "        \n",
    "        df['impact'] = self.label_encoder_impact.transform(df['impact'])\n",
    "        df['urgency'] = self.label_encoder_urgency.transform(df['urgency'])\n",
    "        df['priority'] = self.label_encoder_priority.transform(df['priority'])\n",
    "        \n",
    "        df['sys_updated_at_ms'] = pd.to_datetime(df['sys_updated_at'], unit='ms').astype(np.int64)\n",
    "        \n",
    "        df[self.numerical_features] = self.numerical_standard_scaler.transform(df[self.numerical_features])\n",
    "     \n",
    "        df[[self.temporal_number_features]] = self.temporal_number_scaler.transform(df[self.temporal_number_features])\n",
    "        \n",
    "        df=df.drop(columns = self.columns_to_be_dropped)\n",
    "        \n",
    "        y =  df['time_taken_to_complete']\n",
    "        df = df.drop(['time_taken_to_complete'], axis=1)\n",
    "        \n",
    "\n",
    "        # if any values have 0, that is there are missing, we need to impute them from trained model\n",
    "        if((df[\"assigned_to_num\"] == 0).any()):\n",
    "            df=self.impute_particular_column_with_saved_model(df,\"assigned_to_num\",self.assigned_to_num_rfc)\n",
    "\n",
    "        if((df[\"assignment_group_num\"] == 0).any()):\n",
    "            df=self.impute_particular_column_with_saved_model(df,\"assignment_group_num\",self.assignment_group_num_rfc)\n",
    "            \n",
    "        if((df[\"opened_by_num\"] == 0).any()):\n",
    "            df=self.impute_particular_column_with_saved_model(df,\"opened_by_num\",self.opened_by_num_rfc)\n",
    "            \n",
    "        if((df[\"sys_created_by_num\"] == 0).any()):\n",
    "            df=self.impute_particular_column_with_saved_model(df,\"sys_created_by_num\",self.sys_created_by_num_rfc)\n",
    "            \n",
    "        if((df[\"u_symptom_num\"] == 0).any()):\n",
    "            df=self.impute_particular_column_with_saved_model(df,\"u_symptom_num\",self.u_symptom_num_rfc)\n",
    "            \n",
    "        # if there are still any missing values, impute using simple imputer\n",
    "        df = pd.DataFrame(data=self.most_frequent_simple_imputer_for_zero_value.transform(df), \n",
    "                                        index=df.index, columns = df.columns)\n",
    "        \n",
    "        for col in self.float_data_type_features:\n",
    "            df[col]=df[col].astype(\"float64\")\n",
    "            \n",
    "        for col in self.int_data_type_features:\n",
    "            df[col]=df[col].astype(\"int64\")\n",
    "        \n",
    "        y_pred = self.lgbm_regressor.predict(df)\n",
    "\n",
    "        return \"Prediction: \"+str(y_pred)+\" | Metric(RMSE): \"+str(np.sqrt(mean_squared_error(y, y_pred)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
